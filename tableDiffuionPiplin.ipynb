{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPpmi8jalCZ7Luu1cRAwhxa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/Diffusion-Models/blob/main/tableDiffuionPiplin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a simplified example of how to use a state-of-the-art diffusion model for image generation using the Stable Diffusion model. For a complete and practical implementation, you should use libraries like Hugging Face's diffusers or stable-diffusion-v1 models. Below is a basic example using Hugging Face's diffusers library to generate images:\n",
        "\n",
        "#1. Install Dependencies\n",
        "\n",
        "First, install the necessary libraries:"
      ],
      "metadata": {
        "id": "K9Q7GgZvVMns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuGD1B0NVDEw"
      },
      "outputs": [],
      "source": [
        "pip install diffusers transformers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Code Example\n",
        "\n",
        "Here's how you can use the Stable Diffusion model to generate images:"
      ],
      "metadata": {
        "id": "S2sajk7nViWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# Initialize the Stable Diffusion pipeline\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
        "pipe.to(\"cuda\")  # Move the pipeline to GPU if available\n",
        "\n",
        "# Define the text prompt\n",
        "prompt = \"A beautiful sunset over a mountain range, with vibrant colors and detailed scenery.\"\n",
        "\n",
        "# Generate images\n",
        "with torch.no_grad():\n",
        "    images = pipe(prompt).images\n",
        "\n",
        "# Save or display the generated images\n",
        "for i, image in enumerate(images):\n",
        "    image.save(f\"generated_image_{i}.png\")\n",
        "\n",
        "# If you want to display the image (e.g., in Jupyter Notebook)\n",
        "from PIL import Image\n",
        "image.show()\n"
      ],
      "metadata": {
        "id": "TS3JpLm0VnMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "\n",
        "#Initialize the Pipeline:\n",
        "\n",
        "StableDiffusionPipeline.from_pretrained loads the pre-trained Stable Diffusion model.\n",
        "\n",
        "pipe.to(\"cuda\") moves the model to the GPU for faster inference if a CUDA-capable GPU is available.\n",
        "\n",
        "#Generate Images:\n",
        "\n",
        "pipe(prompt).images generates images based on the provided text prompt.\n",
        "Save or Display Images:\n",
        "\n",
        "You can save the generated images using image.save or display them using image.show()."
      ],
      "metadata": {
        "id": "V9eYC4oUYHfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "The CompVis/stable-diffusion-v1-4 model is used in this example. You may need to adjust the model name based on the available versions or specific requirements.\n",
        "\n",
        "Running diffusion models can be resource-intensive. Ensure your environment has sufficient computational resources, especially for larger models or higher resolution outputs.\n",
        "\n",
        "For a more detailed and customizable implementation, refer to the Hugging Face documentation or other libraries specializing in diffusion models.\n",
        "This example demonstrates a straightforward way to utilize diffusion models for generating images. For more advanced features and options, consider exploring additional settings and configurations available in the diffusers library."
      ],
      "metadata": {
        "id": "qoDXiGGCYb5P"
      }
    }
  ]
}